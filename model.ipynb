{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential, Model\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.optimizers import Adam, SGD\n",
    "from tensorflow.python.keras.activations import relu\n",
    "from tensorflow.python.keras.metrics import categorical_accuracy, mean_squared_error\n",
    "from tensorflow.python.keras.callbacks import BaseLogger, ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.initializers import Ones, Zeros, glorot_normal\n",
    "from tensorflow.python.framework import tensor_shape\n",
    "from data_genration import DataGenerator\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipped_relu(x):\n",
    "    return relu(x, max_value=20)\n",
    "\n",
    "def ctc_lambda_func(args):\n",
    "    labels, y_pred, input_length, label_length = args\n",
    "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
    "\n",
    "def ctc(y_true, y_pred):\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_speech_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Batch normalize the input\n",
    "    model.add(BatchNormalization(axis=-1, input_shape=(None, 161), name='BN_1'))\n",
    "    \n",
    "    # 1D Convs\n",
    "    model.add(Conv1D(512, 5, strides=1, activation=clipped_relu, name='Conv1D_1'))\n",
    "    model.add(Conv1D(512, 5, strides=1, activation=clipped_relu, name='Conv1D_2'))\n",
    "    model.add(Conv1D(512, 5, strides=2, activation=clipped_relu, name='Conv1D_3'))\n",
    "    \n",
    "    # Batch Normalization\n",
    "    model.add(BatchNormalization(axis=-1, name='BN_2'))\n",
    "    \n",
    "    # BiRNNs\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_1'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_2'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_3'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_4'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_5'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_6'), merge_mode='sum'))\n",
    "    model.add(Bidirectional(SimpleRNN(1280, return_sequences=True, name='BiRNN_7'), merge_mode='sum'))\n",
    "    \n",
    "    # Batch Normalization\n",
    "    model.add(BatchNormalization(axis=-1, name='BN_3'))\n",
    "    \n",
    "    # FC\n",
    "    model.add(TimeDistributed(Dense(1024, activation=clipped_relu, name='FC1')))\n",
    "    model.add(TimeDistributed(Dense(29, activation='softmax', name='y_pred')))\n",
    "    return model\n",
    "\n",
    "def get_trainable_speech_model():\n",
    "    model = get_speech_model()\n",
    "    y_pred = model.outputs[0]\n",
    "    model_input = model.inputs[0]\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    labels = Input(name='the_labels', shape=[None,], dtype='int32')\n",
    "    input_length = Input(name='input_length', shape=[1], dtype='int32')\n",
    "    label_length = Input(name='label_length', shape=[1], dtype='int32')\n",
    "\n",
    "    loss_out = Lambda(ctc_lambda_func, name='ctc')([labels, y_pred, input_length, label_length])\n",
    "    trainable_model = Model(inputs=[model_input, labels, input_length, label_length], outputs=loss_out)\n",
    "    return trainable_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nBN_1 (BatchNormalization)    (None, None, 161)         644       \n_________________________________________________________________\nConv1D_1 (Conv1D)            (None, None, 512)         412672    \n_________________________________________________________________\nConv1D_2 (Conv1D)            (None, None, 512)         1311232   \n_________________________________________________________________\nConv1D_3 (Conv1D)            (None, None, 512)         1311232   \n_________________________________________________________________\nBN_2 (BatchNormalization)    (None, None, 512)         2048      \n_________________________________________________________________\nbidirectional (Bidirectional (None, None, 1280)        4590080   \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, None, 1280)        6556160   \n_________________________________________________________________\nbidirectional_2 (Bidirection (None, None, 1280)        6556160   \n_________________________________________________________________\nbidirectional_3 (Bidirection (None, None, 1280)        6556160   \n_________________________________________________________________\nbidirectional_4 (Bidirection (None, None, 1280)        6556160   \n_________________________________________________________________\nbidirectional_5 (Bidirection (None, None, 1280)        6556160   \n_________________________________________________________________\nbidirectional_6 (Bidirection (None, None, 1280)        6556160   \n_________________________________________________________________\nBN_3 (BatchNormalization)    (None, None, 1280)        5120      \n_________________________________________________________________\ntime_distributed (TimeDistri (None, None, 1024)        1311744   \n_________________________________________________________________\ntime_distributed_1 (TimeDist (None, None, 29)          29725     \n=================================================================\nTotal params: 48,311,457\nTrainable params: 48,307,551\nNon-trainable params: 3,906\n_________________________________________________________________\nModel: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\nBN_1_input (InputLayer)         [(None, None, 161)]  0                                            \n__________________________________________________________________________________________________\nBN_1 (BatchNormalization)       (None, None, 161)    644         BN_1_input[0][0]                 \n__________________________________________________________________________________________________\nConv1D_1 (Conv1D)               (None, None, 512)    412672      BN_1[0][0]                       \n__________________________________________________________________________________________________\nConv1D_2 (Conv1D)               (None, None, 512)    1311232     Conv1D_1[0][0]                   \n__________________________________________________________________________________________________\nConv1D_3 (Conv1D)               (None, None, 512)    1311232     Conv1D_2[0][0]                   \n__________________________________________________________________________________________________\nBN_2 (BatchNormalization)       (None, None, 512)    2048        Conv1D_3[0][0]                   \n__________________________________________________________________________________________________\nbidirectional (Bidirectional)   (None, None, 1280)   4590080     BN_2[0][0]                       \n__________________________________________________________________________________________________\nbidirectional_1 (Bidirectional) (None, None, 1280)   6556160     bidirectional[0][0]              \n__________________________________________________________________________________________________\nbidirectional_2 (Bidirectional) (None, None, 1280)   6556160     bidirectional_1[0][0]            \n__________________________________________________________________________________________________\nbidirectional_3 (Bidirectional) (None, None, 1280)   6556160     bidirectional_2[0][0]            \n__________________________________________________________________________________________________\nbidirectional_4 (Bidirectional) (None, None, 1280)   6556160     bidirectional_3[0][0]            \n__________________________________________________________________________________________________\nbidirectional_5 (Bidirectional) (None, None, 1280)   6556160     bidirectional_4[0][0]            \n__________________________________________________________________________________________________\nbidirectional_6 (Bidirectional) (None, None, 1280)   6556160     bidirectional_5[0][0]            \n__________________________________________________________________________________________________\nBN_3 (BatchNormalization)       (None, None, 1280)   5120        bidirectional_6[0][0]            \n__________________________________________________________________________________________________\ntime_distributed (TimeDistribut (None, None, 1024)   1311744     BN_3[0][0]                       \n__________________________________________________________________________________________________\nthe_labels (InputLayer)         [(None, None)]       0                                            \n__________________________________________________________________________________________________\ntime_distributed_1 (TimeDistrib (None, None, 29)     29725       time_distributed[0][0]           \n__________________________________________________________________________________________________\ninput_length (InputLayer)       [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nlabel_length (InputLayer)       [(None, 1)]          0                                            \n__________________________________________________________________________________________________\nctc (Lambda)                    (None, 1)            0           the_labels[0][0]                 \n                                                                 time_distributed_1[0][0]         \n                                                                 input_length[0][0]               \n                                                                 label_length[0][0]               \n==================================================================================================\nTotal params: 48,311,457\nTrainable params: 48,307,551\nNon-trainable params: 3,906\n__________________________________________________________________________________________________\n"
    }
   ],
   "source": [
    "model = get_trainable_speech_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36864bit1f6584a510a843b7888176314c46071f",
   "display_name": "Python 3.6.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}